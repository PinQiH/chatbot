import streamlit as st
from openai import OpenAI
import matplotlib.pyplot as plt
import requests

# å‡è¨­é€™æ˜¯å­˜å„²åœ¨æŸå€‹åœ°æ–¹çš„èŠå¤©æ­·å²æ•¸æ“š
chat_history = {
    "History1": {
        "messages": [
            {"role": "assistant", "content": "Hello, how can I help?"},
            {"role": "user", "content": "What is the weather today?"},
            {"role": "assistant", "content": "Today is a sunny day.", "source": ["ä»Šå¤©çš„å¤©æ°£å¦‚ä¸‹ï¼šç¾åœ¨å¤©æ°£ï¼šè¼•é›¨ï¼Œæ”æ° 30 åº¦ã€‚æœ€é«˜æº«åº¦ï¼š31 åº¦ã€‚æœ€ä½æº«åº¦ï¼š22 åº¦ã€‚æ—¥å‡ºæ™‚é–“ï¼šä¸Šåˆ 5:24ã€‚æ—¥è½æ™‚é–“ï¼šä¸‹åˆ 6:20ã€‚"]},
        ],
        "model": "gpt-3.5-turbo",
        "databases": ["Database 1"]
	},
    "History2": {
		"messages": [
			{"role": "assistant", "content": "Hello, how can I help?"},
			{"role": "user", "content": "Can you book a flight for me?"},
			{"role": "assistant", "content": "Sure, where would you like to go?"}
		],
        "model": "gpt-3.5-turbo",
        "databases": ["Database 2"]
	},
    "History3": {
		"messages": [
			{"role": "assistant", "content": "Hello, how can I help?"},
			{"role": "user", "content": "What's the currency rate for EUR to USD?"},
			{"role": "assistant", "content": "As of today, it is 1.13.", "source": ["ä»Šå¤©çš„ æ­å…ƒ (EUR) å…Œ ç¾å…ƒ (USD) åŒ¯ç‡ç‚º 1 æ­å…ƒ = 1.07 ç¾å…ƒ", "https://www.bing.com/search?q=EUR+to+USD+currency+rate&FORM=wndcht&toWww=1&redig=25FDF18430034C909422C59892119F36"]}
		],
        "model": "gpt-3.5-turbo",
        "databases": ["Database 3"]
	},
    "History4": {
		"messages": [
			{"role": "assistant", "content": "Hello, how can I help?"},
			{"role": "user", "content": "I need directions to the nearest hospital."},
			{"role": "assistant", "content": "Here is the map for the nearest hospital.","source": ["è‡ºåŒ—å¸‚ç«‹è¯åˆé†«é™¢ä¸­èˆˆé™¢å€ï¼šåœ°å€ï¼šè‡ºåŒ—å¸‚å¤§åŒå€é„­å·è·¯145è™Ÿé›»è©±ï¼š02 2552 3234", "è¥¿åœ’é†«é™¢ï¼šåœ°å€ï¼šè‡ºåŒ—å¸‚è¬è¯å€è¥¿åœ’è·¯äºŒæ®µ270è™Ÿé›»è©±ï¼š02 2307 6968"]}
		],
        "model": "gpt-4",
        "databases": ["Database 1", "Database 2"]
	},
    "History5": {
		"messages": [
			{"role": "assistant", "content": "Hello, how can I help?"},
			{"role": "user", "content": "Can you play some music?"},
			{"role": "assistant", "content": "Playing your favorite playlist now."}
		],
		"model": "Taiwan-LLM-13B-2.0-chat",
		"databases": ["Database 1", "Database 2", "Database 3"]
	}
}

# å‡è¨­é€™æ˜¯å¯é¸æ“‡çš„åŠ©ç†æ¨¡å‹å’Œæ•¸æ“šåº«ä¾†æº
assistant_models = ["gpt-3.5-turbo", "gpt-4", "yabi/breeze-7b-instruct-v1_0_q6_k", "jcai/taide-lx-7b-chat:latest", "llama3:latest"]
database_sources = ["Database 1", "Database 2", "Database 3"]

# ç™»å…¥æª¢æŸ¥å’Œè™•ç†å‡½æ•¸
def check_login(username, password):
    # é€™è£¡æ‡‰è©²æ˜¯ä½ çš„ç™»å…¥é‚è¼¯
    # å¦‚æœç™»å…¥æˆåŠŸï¼Œè¿”å› True
    # é€™è£¡æˆ‘å‡è¨­ä»»ä½•éç©ºçš„ç”¨æˆ¶åå’Œå¯†ç¢¼éƒ½ä»£è¡¨ç™»å…¥æˆåŠŸ
    return username != "" and password != ""

def generate_ollama_text(model, prompt):
    url = "http://localhost:11434/api/generate"
    data = {
        "model": model,
        "prompt": prompt,
        "stream": False,
    }
    response = requests.post(url, json=data)
    if response.status_code == 200:
        return response.json().get('response', 'ç„¡è¿”å›éŸ¿æ‡‰ã€‚')
    else:
        return f'ç™¼ç”ŸéŒ¯èª¤: {response.status_code}'

# å»ºç«‹å´é‚Šæ¬„ä¸¦è¼¸å…¥ API Key
with st.sidebar:
	st.header("ç¶“æ¿Ÿçµ±è¨ˆæ™ºæ…§å®¢æœ")

	if st.button("ğŸ’¬ Start New Chat", key="new_chat"):
			# æ¸…ç©ºèŠå¤©è¨˜éŒ„æˆ–åŸ·è¡Œé–‹å•Ÿæ–°èŠå¤©çš„é‚è¼¯
			st.session_state.messages = [{"role": "assistant", "content": "How can I help you?"}]
			st.session_state.current_history = "ğŸ’¬ Chatbot"
			if 'model_choice' in st.session_state:
				del st.session_state.model_choice
			if 'database_choices' in st.session_state:
				del st.session_state.database_choices
			st.session_state.selection_locked = False
			st.rerun()

	# å¢åŠ ç™»å…¥é¸é …
	# å¦‚æœå·²ç¶“ç™»å…¥ï¼Œé¡¯ç¤ºç”¨æˆ¶åï¼Œå¦å‰‡é¡¯ç¤ºç™»å…¥è¡¨å–®
	if 'logged_in' in st.session_state and st.session_state.logged_in:
		# æ­·å²ç´€éŒ„é¸å–®
		with st.expander("ğŸ“œ History"):
			for history_key in chat_history:
					if st.button(history_key, key=history_key):
						# æ¢å¾©è¨Šæ¯å’Œç•¶æ™‚çš„è¨­å®š
						st.session_state.messages = chat_history[history_key]["messages"]
						st.session_state.current_history = history_key
						st.session_state.model_choice = chat_history[history_key]["model"]
						st.session_state.database_choices = chat_history[history_key]["databases"]

		# å¢åŠ ä½¿ç”¨é‡è¨­å®šé¸é …
		with st.expander("ğŸ“Š Usage Settings"):
			current_usage = 750
			st.write(f"ç›®å‰ä½¿ç”¨é‡: {current_usage} token")
			usage_limit = st.number_input("è¨­å®šä½¿ç”¨é‡ä¸Šé™", min_value=0, value=1000, step=50, format="%d", key="usage_limit")
			# å‰µå»ºæ•¸æ“šä»¥åŠæ¨™ç±¤
			data = [current_usage, usage_limit - current_usage]
			labels = ['Used Tokens', 'Remaining Tokens']

			# ç¹ªè£½åœ“é¤…åœ–
			fig, ax = plt.subplots()
			ax.pie(data, labels=labels, autopct='%1.1f%%', startangle=90)
			ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

			# é¡¯ç¤ºåœ“é¤…åœ–
			st.pyplot(fig)
			alert_usage = st.checkbox("ä½¿ç”¨é‡ç¤ºè­¦")
			if st.button("Save Usage Settings", key="save_usage"):
					st.write("Save logic goes here")

		with st.expander(f"ğŸ‘¤ {st.session_state.username}"):
			st.write("You are logged in.")
			if st.button('Logout'):
				st.session_state.logged_in = False
				st.session_state.username = ''
				st.experimental_rerun()
	else:
		with st.expander("ğŸ” Login"):
			username = st.text_input("Username")
			password = st.text_input("Password", type="password")
			if st.button("Login", key="login"):
				if check_login(username, password):
					st.session_state.logged_in = True
					st.session_state.username = username
					st.write(f"Welcome {username}!")
					st.experimental_rerun()
				else:
					st.error("Login failed.")
	
	# å¢åŠ API keyè¨­å®šé¸é …
	with st.expander("ğŸ”‘ API Key Settings"):
		openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
		"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"
		if st.button("Save API key Settings", key="save_api"):
				st.write("Save success")
			
# å‰µå»ºä¸‰å€‹ä¸¦æ’çš„åˆ—
col1, col2, col3 = st.columns(3)

# åœ¨ç¬¬ä¸€åˆ—ä¸­æ”¾ç½®æ¨™é¡Œ
with col1:
	# ä¸»è¦å…§å®¹å€
	current_title = st.session_state.get('current_history', 'ğŸ’¬Chatbot')
	st.title(current_title)

# å¦‚æœå·²ç¶“é–‹å§‹èŠå¤©ï¼ˆmessages è‡³å°‘æœ‰ä¸€æ¢è¨Šæ¯ï¼‰ï¼Œå‰‡ç¦ç”¨é¸é …
disable_selection = "selection_locked" in st.session_state and st.session_state.selection_locked

# åœ¨ç¬¬äºŒåˆ—ä¸­æ”¾ç½®é¸æ“‡åŠ©ç†æ¨¡å‹çš„ä¸‹æ‹‰é¸å–®
with col2:
    # ä¸‹æ‹‰é¸å–®ä¾†é¸æ“‡åŠ©ç†æ¨¡å‹
    default_model = st.session_state.get('model_choice', assistant_models[0])
    model_choice = st.selectbox(
        "Choose an assistant model:", 
        assistant_models, 
        index=assistant_models.index(default_model), 
        disabled=disable_selection
    )

# åœ¨ç¬¬ä¸‰åˆ—ä¸­æ”¾ç½®é¸æ“‡æ•¸æ“šåº«ä¾†æºçš„å¤šé¸ä¸‹æ‹‰é¸å–®
with col3:
    # ä¸‹æ‹‰é¸å–®ä¾†é¸æ“‡æ•¸æ“šåº«ä¾†æº
    default_databases = st.session_state.get('database_choices', database_sources)
    database_choices = st.multiselect(
        "Choose database sources:", 
        database_sources, 
        default=default_databases, 
        disabled=disable_selection
    )

# åˆå§‹è¨Šæ¯ç®¡ç†
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

# é¡¯ç¤ºèŠå¤©è¨Šæ¯
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])
    if 'source' in msg:
        sources = msg['source']
        for source in sources:
            if "http" in source:
                st.markdown(f"[Source]({source})", unsafe_allow_html=True)
            else:
                st.write(f"Source: {source}")

# è™•ç†æ–°çš„èŠå¤©è¼¸å…¥
if prompt := st.chat_input():
    st.session_state.model_choice = model_choice
    st.session_state.database_choices = database_choices
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    if "gpt" not in model_choice:
        response = generate_ollama_text(model_choice, prompt)
    else:
        if not openai_api_key:
            st.info("Please add your OpenAI API key to continue.")
            st.stop()
        client = OpenAI(api_key=openai_api_key)
        response = client.chat.completions.create(model=model_choice, messages=st.session_state.messages)
        response = response.choices[0].message.content

    st.session_state.messages.append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)

    st.session_state.selection_locked = True
